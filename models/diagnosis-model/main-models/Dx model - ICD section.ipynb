{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pandasql import sqldf\n",
    "from scipy import stats\n",
    "import time\n",
    "import networkx as nx\n",
    "import simple_icd_10_cm as cm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_pats = 120000 # CHOOSE\n",
    "dataset_loc = '...' # Insert path to preprocessed csv\n",
    "\n",
    "# Additional preprocessing\n",
    "\n",
    "dx_df2 = pd.read_csv(dataset_loc)\n",
    "icd_list_text = dx_df2['section'].value_counts()[:50].index # List of ICD-10 sections to use as nodes in network (top 50)\n",
    "pats = np.random.choice(dx_df2['patid'].unique(), num_pats, replace=False) # Choose random patients to use\n",
    "dx_df = dx_df2[dx_df2['patid'].isin(pats)]\n",
    "dx_df = dx_df.reset_index(drop=True)\n",
    "\n",
    "# Create section to section_int lookup\n",
    "lookup = dx_df.groupby(['section', 'section_int']).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "# Convert list of ICD-10 sections to integers\n",
    "icd1_list = []\n",
    "icd2_list = []\n",
    "for icd in icd_list_text:\n",
    "    to_add = lookup[lookup['section']==icd]['section_int'].tolist()[0] \n",
    "    icd1_list.append(to_add)\n",
    "    icd2_list.append(to_add)\n",
    "\n",
    "# Model\n",
    "\n",
    "result = []\n",
    "for icd2 in icd2_list: # Cycle through icd2_list\n",
    "    # Create dataframe which includes flag if patient in row is diagnosed with D2 within 5 years\n",
    "    q = \"\"\"\n",
    "    SELECT *, ep2_icd IS NOT NULL FROM (\n",
    "    SELECT a.*, b.patid AS patid_dup, b.section_int AS ep2_icd, b.epistart as ep2_start\n",
    "    FROM dx_df AS a\n",
    "    LEFT JOIN dx_df AS b\n",
    "    ON a.patid = b.patid\n",
    "    AND b.epistart > a.epistart\n",
    "    AND julianday(b.epistart) - julianday(a.epistart) < 1825\n",
    "    AND b.section_int = {}\n",
    "    LIMIT 100000000) AS T\n",
    "    LIMIT 100000000;\n",
    "    \"\"\".format(icd2)\n",
    "    df = sqldf(q)\n",
    "\n",
    "    # Convert epistart column to datetime datatype\n",
    "    df['epistart'] = pd.to_datetime(df['epistart'])\n",
    "    \n",
    "    for icd1 in icd1_list: # Cycle through icd1_list\n",
    "        if icd1 == icd2:\n",
    "            continue # Skip to next iteration if icd1 == icd2\n",
    "        \n",
    "        # Dataframe for all D1 patients, with those leading to icd2 indicated\n",
    "        D1_patients = df.loc[df['section_int'] == icd1]\n",
    "\n",
    "        # Find earliest episode with D1 per patient\n",
    "        D1_patients = D1_patients.loc[D1_patients.groupby('patid').epistart.idxmin()]\n",
    "\n",
    "        # Total D1 patients which lead to D2\n",
    "        num_D1_to_D2 = D1_patients['ep2_icd IS NOT NULL'].sum()\n",
    "        \n",
    "        Total_D1_patients = len(D1_patients)\n",
    "        \n",
    "        dx_pair_result = []\n",
    "        dx_pair_result.append(lookup[lookup['section_int']==icd1]['section'].tolist()[0])\n",
    "        dx_pair_result.append(lookup[lookup['section_int']==icd2]['section'].tolist()[0])\n",
    "        dx_pair_result.append(Total_D1_patients)\n",
    "        dx_pair_result.append(num_D1_to_D2)\n",
    "        result.append(dx_pair_result)\n",
    "\n",
    "MainResult = pd.DataFrame(result)\n",
    "print(\"Main model finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matched dataset\n",
    "dx_df['epistart'] = pd.to_datetime(dx_df['epistart'])\n",
    "matched_rows = []\n",
    "for row in dx_df.itertuples(index=False, name='Pandas'):\n",
    "    try: # Find rows similar to row in original dataframe subject to conditions\n",
    "        matched_rows.append(dx_df[\n",
    "        (row[2] - pd.Timedelta(days = 30) < dx_df['epistart']) &\n",
    "        (dx_df['epistart'] < row[2] + pd.Timedelta(days = 30)) &\n",
    "        (dx_df['gender'] == row[5]) &\n",
    "        (row[6] - 5 < dx_df['yob']) &\n",
    "        (dx_df['yob'] < row[6] + 5) &\n",
    "        (dx_df['gen_ethnicity_int'] == row[12]) &\n",
    "        (dx_df['section_int'] != row[14]) & \n",
    "        (dx_df['patid'] != row[0]) &\n",
    "        (dx_df['IP?'] == row[9])\n",
    "        ].sample(1))\n",
    "    except:\n",
    "        # If no matches, add a blank row\n",
    "        matched_rows.append(pd.DataFrame(np.array([-1,0,'2000-01-01',0,0,0,0,'NO MATCH',0,0,0,'NO MATCH',\n",
    "                            0,0,0],ndmin=2), columns = \n",
    "                                         ['patid','icd', 'epistart', 'spno', 'num', \n",
    "                                          'gender', 'yob', 'gen_ethnicity', 'admimeth',\n",
    "                                          'IP?', 'chapter', 'section', 'gen_ethnicity_int', 'icd_int',\n",
    "                                          'section_int']))\n",
    "# Convert to dataframe\n",
    "matched_df = pd.DataFrame(np.array(matched_rows).squeeze(), columns = ['patid','icd', 'epistart', 'spno', 'num', \n",
    "                                          'gender', 'yob', 'gen_ethnicity', 'admimeth',\n",
    "                                          'IP?', 'chapter', 'section', 'gen_ethnicity_int', 'icd_int',\n",
    "                                          'section_int'])\n",
    "# Change column types\n",
    "matched_df = matched_df.astype({'patid': 'int64', 'spno': 'int64',\n",
    "             'gender': 'int64', 'yob': 'int64', 'IP?': 'int64', 'num': 'int64',\n",
    "             'chapter': 'int64', 'gen_ethnicity_int': 'int64', 'section_int': 'int64',\n",
    "             'icd_int': 'int64'})\n",
    "\n",
    "# Rename columns\n",
    "matched_df = matched_df.rename(columns={\"patid\": \"m_patid\", \"spno\": \"m_spno\", \"epikey\": \"m_epikey\", \"epistart\": \"m_epistart\", \"epiend\": \"m_epiend\",\n",
    "                          \"icd\": \"m_icd\", \"icdx\": \"m_icdx\", \"d_order\": \"m_d_order\", \"gender\": \"m_gender\", \"yob\": \"m_yob\",\n",
    "                          \"gen_ethnicity\": \"m_gen_ethnicity\", \"dismeth\": \"m_dismeth\", \"admimeth\": \"m_admimeth\", \"IP?\": \"m_IP?\",\n",
    "                          \"chapter\": \"m_chapter\", \"section\": \"m_section\", \"gen_ethnicity_int\": \"m_gen_ethnicity_int\",\n",
    "                          \"section_int\": \"m_section_int\", \"icd_int\": \"m_icd_int\", \"num\": \"m_num\"})\n",
    "\n",
    "print(\"matched df constructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of matched patients who are diagnosed with D2 within 5 years\n",
    "\n",
    "# Join original and matched dataframes\n",
    "fulldf = pd.concat([dx_df, matched_df], axis=1, join=\"inner\")\n",
    "\n",
    "# Convert date columns to datetime datatype\n",
    "fulldf['epistart'] = pd.to_datetime(fulldf['epistart'])\n",
    "fulldf['m_epistart'] = pd.to_datetime(fulldf['m_epistart'])\n",
    "\n",
    "result = []\n",
    "for icd2 in icd2_list: # Cycle through icd2_list\n",
    "    # Create dataframe which includes flag if patient in row is diagnosed with D2 within 5 years\n",
    "    q = \"\"\"\n",
    "    SELECT *, ep2_icd IS NOT NULL FROM (\n",
    "    SELECT a.*, b.patid AS patid_dup, b.section as ep2_icd, b.section_int AS ep2_icd_int, b.epistart as ep2_start \n",
    "    FROM fulldf AS a\n",
    "    LEFT JOIN dx_df AS b\n",
    "    ON a.m_patid = b.patid\n",
    "    AND b.epistart > a.m_epistart\n",
    "    AND julianday(b.epistart) - julianday(a.m_epistart) < 1825\n",
    "    AND b.section_int = {}\n",
    "    LIMIT 100000000) AS T\n",
    "    LIMIT 100000000;\n",
    "    \"\"\".format(icd2)\n",
    "    df = sqldf(q)\n",
    "    \n",
    "    # Convert epistart column to datetime datatype\n",
    "    df['epistart'] = pd.to_datetime(df['epistart'])\n",
    "    \n",
    "    for icd1 in icd1_list:\n",
    "        if icd1 == icd2:\n",
    "            continue # Skip to next iteration if icd1 == icd2\n",
    "        \n",
    "        # Dataframe for all D1 patients with their matches and those leading to D2 indicated\n",
    "        D1_patients = df.loc[df['section_int'] == icd1]\n",
    "\n",
    "        # Find earliest episode with D1 per patient\n",
    "        D1_patients = D1_patients.loc[D1_patients.groupby('patid').epistart.idxmin()]\n",
    "        \n",
    "        # Filter out NO MATCH rows\n",
    "        D1_patients = D1_patients[D1_patients[\"m_patid\"]!=-1]\n",
    "\n",
    "        # Total D1 patients which lead to D2\n",
    "        num_D1_to_D2 = D1_patients['ep2_icd IS NOT NULL'].sum()\n",
    "        \n",
    "        dx_pair_result = []\n",
    "        dx_pair_result.append(lookup[lookup['section_int']==icd1]['section'].tolist()[0])\n",
    "        dx_pair_result.append(lookup[lookup['section_int']==icd2]['section'].tolist()[0])\n",
    "        D1_V2 = D1_patients[D1_patients['m_section_int']!=icd2] # Filter out rows where matched diagnosis == D2\n",
    "        dx_pair_result.append(len(D1_V2))\n",
    "        dx_pair_result.append(D1_V2['ep2_icd IS NOT NULL'].sum())\n",
    "        \n",
    "        result.append(dx_pair_result)\n",
    "\n",
    "MatchResult = pd.DataFrame(result) # Convert results to dataframe \n",
    "MainResult = MainResult.rename(columns = {0:'D1', 1:'D2', 2:'Total_D1_patients', 3:'D1toD2'})\n",
    "MatchResult = MatchResult.rename(columns = {0:'D1', 1:'D2', 2:'matchlen', 3:'matchtoD2'})\n",
    "\n",
    "# Combine results into one df\n",
    "MainResult = pd.concat([MainResult, MatchResult['matchlen']], axis=1)\n",
    "MainResult = pd.concat([MainResult, MatchResult['matchtoD2']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate relative risk as well as RR confidence intervals\n",
    "\n",
    "def RelRisk(row):\n",
    "    if row['matchtoD2'] > 0:\n",
    "        return (row['D1toD2']/row['Total_D1_patients'])/(row['matchtoD2']/row['matchlen'])\n",
    "    else:\n",
    "        return 1\n",
    "MainResult['RR'] = MainResult.apply(lambda row: RelRisk(row), axis=1)\n",
    "\n",
    "def LogCI(row): # Calculate SE(log(RR))\n",
    "    if row['matchtoD2'] == 0 or row['D1toD2'] == 0:\n",
    "        return float(\"inf\")\n",
    "    else:\n",
    "        return np.sqrt(1/row['D1toD2']-1/row['Total_D1_patients']+1/row['matchtoD2']-1/row['matchlen'])\n",
    "    \n",
    "MainResult['Log_CI'] = MainResult.apply(lambda row: LogCI(row), axis=1)\n",
    "\n",
    "def CImin(row): # Lower bound for CI\n",
    "    if row['RR']-4.26*row['Log_CI']>=0: # Change 4.26 to appropriate (Bonferroni-corrected) z-score\n",
    "        return np.exp(np.log(row['RR']-4.26*row['Log_CI']))\n",
    "    else:\n",
    "        return 0\n",
    "MainResult['CImin'] = MainResult.apply(lambda row: CImin(row), axis=1)\n",
    "\n",
    "def CImax(row): # Upper bound for CI\n",
    "    if row['RR']+4.26*row['Log_CI']>=0:\n",
    "        return np.exp(np.log(row['RR']+4.26*row['Log_CI']))\n",
    "    else:\n",
    "        return 10\n",
    "MainResult['CImax'] = MainResult.apply(lambda row: CImax(row), axis=1)\n",
    "\n",
    "def CIover1(row): # Indicate if CI crosses over 1\n",
    "    if row['CImin'] <= 1 and row['CImax'] <= 1:\n",
    "        return 1\n",
    "    elif row['CImin'] >= 1 and row['CImax'] >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "MainResult['CIover1'] = MainResult.apply(lambda row: CIover1(row), axis=1)\n",
    "\n",
    "def CIsize(row):\n",
    "    if row['CImax'] == float(\"inf\"):\n",
    "        return 10\n",
    "    else:\n",
    "        return row['CImax'] - row['CImin']\n",
    "MainResult['CIsize'] = MainResult.apply(lambda row: CIsize(row), axis=1)\n",
    "\n",
    "# Save to csv\n",
    "# MainResult.to_csv('ICDSec{}Results.csv'.format(num_pats), index=False)\n",
    "\n",
    "# Final result metrics to report\n",
    "metrics = []\n",
    "metrics.append(len(fulldf)) # Total dataset size\n",
    "metrics.append(1-np.sum(matched_df['m_patid']==-1)/len(matched_df)) # Percentage of matched patients found\n",
    "metrics.append(np.mean(MainResult['CIsize'])) # Av RR interval size\n",
    "metrics.append(np.sum(MainResult['CIover1'])/len(MainResult)) # Percentage CIs that do not cross 1\n",
    "# pd.DataFrame(metrics).to_csv('ICDSec{}Metrics.csv'.format(num_pats), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results with another network\n",
    "\n",
    "df1 = MainResult\n",
    "df2 = pd.read_csv('...') # Load another network\n",
    "# Compare adjacency matrices using various metrics\n",
    "df1 = df1.rename(columns={'RR':\"RR2\"}) # Change column name so no clash\n",
    "df2 = pd.concat([df1['RR2'], MainResult['RR']], axis=1, join=\"inner\")\n",
    "dists = []\n",
    "dists.append(np.sqrt(np.sum(df2.apply(lambda row: (row['RR2']-row['RR'])**2 ,axis=1)))) # Euclidean\n",
    "dists.append(np.sum(df2.apply(lambda row: abs(row['RR2']-row['RR']) ,axis=1))) # Manhattan\n",
    "dists.append(1-np.sum(df2.apply(lambda row: min(row['RR2'],row['RR']),axis=1))/np.sum(df2.apply(lambda row: max(row['RR2'],row['RR']),axis=1))) # Weighted Jaccard\n",
    "# pd.DataFrame(dists).to_csv('...'.format(num_pats), index=False) # Save distance metric results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
